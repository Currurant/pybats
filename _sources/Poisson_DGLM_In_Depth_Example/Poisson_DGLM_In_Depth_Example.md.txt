
# Sales Forecasting: In-Depth Example

In this example we will model a simulated sales dataset. We will use a Poisson DGLM:

$$y_t \sim Pois(\mu_t)$$
$$\log(\mu_t) = \lambda_t$$
$$\lambda_t = F_t^{'} \theta_t$$


Where $\theta_t$ is the state vector. Our model has the follow _dynamic_ components:
- Trend: 1 intercept term
- Regression: 2 regression terms for Price and a 0-1 indicator for any sales or promotions.
- Holidays: 10 holidays are added. These also act as regression terms, with a 0-1 indicator for each holiday.
- Seasonality: A seasonal component with period 7 for the day-of-the-week. For this term we use the 3 harmonic components, which means there are 6 coefficients. We will demonstrate how to translate the coefficients into 7 values, one for each day of the week.


```python
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from pandas.tseries.holiday import USFederalHolidayCalendar
from pybats.analysis import analysis
from pybats.point_forecast import median
from pybats.plot import plot_data_forecast, ax_style, plot_coef
from pybats.shared import load_sales_example2
```

### Load in the data


```python
data = load_sales_example2()
data = data.set_index('Date')
data.head()
```
| Date       | Sales | Price | Promotion |
|------------|-------|-------|-----------|
| 2014-06-01 | 6     | -0.03 | 0         |
| 2014-06-02 | 10    | 0.14  | 0         |
| 2014-06-03 | 8     | -0.09 | 0         |


### Run the analysis

The analysis function is pybats is meant to provide an easy interface that will:
- Define a model prior
- Run an analysis
- Return forecast results

We must choose the form of the model we want, and we'll define the model form discussed above. We also have to set a few parameters that specify what dates we want to forecast, and what forecast horizon we're considering.


```python
prior_length = 21   # Number of days of data used to set prior
k = 7               # Forecast horizon
rho = 0.5           # Random effect discount factor to increase variance of forecast distribution
forecast_samps = 2000  # Number of forecast samples to draw
forecast_start = pd.to_datetime('2017-01-01') # Date to start forecasting
forecast_end = pd.to_datetime('2018-05-24')   # Date to stop forecasting
```


```python
mod, samples, model_coef = analysis(data.Sales.values, data[['Price', 'Promotion']].values,
                        k, forecast_start, forecast_end, nsamps=forecast_samps,
                        family='poisson',
                        seasPeriods=[7], seasHarmComponents=[[1,2,3]],
                        prior_length=prior_length, dates=data.index, holidays=USFederalHolidayCalendar.rules,
                        rho=rho,
                        ret = ['model', 'forecast', 'model_coef'])
```

    beginning forecasting


We specified the desired output with the argument 'ret'. We have:
- The model, which has been sequentially updated through to the date 'forecast_end'. The most interested model component is the posterior mean and covariance of the state vector: mod.m, mod.C
- The forecast samples. Each day in the range forecast_start to forecast_end, the model draws forecast samples 'k' steps ahead. Therefore samples is of shape (forecast_samps * forecast_length * k).
- The model coefficients. Not part of the default output from the analysis function, but in this case we are interested in how the day-of-week effect changes over time, we so we have saved the complete history of the state vector. This contains the posterior means and variances.

### Plot the forecast results

Now we'll plot the forecasts. Let's start with the 1-step ahead forecasts:


```python
data_1step = data.loc[forecast_start:forecast_end]
samples_1step = samples[:,:,0]
fig, ax = plt.subplots(1,1)
ax = plot_data_forecast(fig, ax,
                        data_1step.Sales,
                        median(samples_1step),
                        samples_1step,
                        data_1step.index,
                        credible_interval=75)
```


```python
plt.show(fig)
```


![png](output_13_0.png)


We're plotting the median forecasts along with the $75\%$ credible intervals. One very clear pattern is the weekly effect, with a weekly spike in our forecasts. There's also a very noticable holiday effect - sales are unpredictable on holidays, and our credible intervals become very large.

You're probably wondering: How accurate are those point forecasts?


```python
from pybats.loss_functions import MAD, ZAPE
print(MAD(data_1step.Sales, median(samples_1step)))
print(ZAPE(data_1step.Sales, median(samples_1step)))
```

    2.37328094303
    37.0121435617


The first loss function is the Mean Absolute Deviation (MAD). Note that we're using the median for our point forecast - it turns out that the median is the optimal forecast for minimizing the MAD, just as the mean is optimal for minimizing the Mean Square Error (MSE).

The second number is the Zero-Adjusted Absolute Percent Error (ZAPE). This is equivalent to the MAPE (Mean Absolute Percent Error), but is still defined even when the sales are 0. On days when sales are 0, then the ZAPE loss is equal to the forecast. Interpreting this as a percent error metric, we're off by a significant margin - but not bad for noisy sales data either! The median is not the optimal forecast to minimize ZAPE, but it's a simple and easy point forecast to obtain.


```python
data_1step = data.loc[forecast_end-pd.DateOffset(60):forecast_end]
samples_1step = samples[:,-61:,0]
fig, ax = plt.subplots(1,1)
ax = plot_data_forecast(fig, ax,
                        data_1step.Sales,
                        median(samples_1step),
                        samples_1step,
                        data_1step.index,
                        credible_interval=75)
```


```python
plt.show(fig)
```


![png](output_18_0.png)


These forecasts look pretty good! Our $75\%$ credible intervals capture the true sales most of the time, as it should.  The weekly pattern is much more clearly visible here.

What if we want to monitor the day-of-week effects? It looks like they're changing over time - what days are become more or less popular? Well, that's why we saved the model coefficients, so we can answer exactly that question!

### Plotting the day-of-week seasonality

We start by taking the posterior coefficents and only looking at the 6 seasonal coefficients, using the 'mod.iseas' property to get the indices for the seasonal components.

Then, we transform these harmonic seasonal components into interpretable coefficients for the 7 days of the week. 


```python
harm_post_mean = coef['m'][:,mod.iseas[0]]
dow_post_mean = mod.L[0] @ harm_post_mean.T
```

Next, we'll align these 7 components with the days of the week, and plot the posterior mean of the coefficients over time. Unfortunately, the structure of the seasonal components means that even after the transformation, the days are rotated. The 'current' day will always appear first in each row in the matrix, so we're going to pluck only that day.


```python
def order_dow(seas_eff, date):
    day = date.dayofweek
    out = np.zeros(7)
    out[day] = seas_eff[0]
    return(out)
```


```python
dow_post_mean_plot = pd.DataFrame([order_dow(seas_eff, date) for seas_eff, date in zip(dow_post_mean.T, data.loc[:forecast_end].index)])
dow_post_mean_plot = dow_post_mean_plot.replace(to_replace=0, method='bfill')
```


```python
days = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']
```


```python
fig, ax = plt.subplots(1,1)
ax = plot_coef(fig, ax, dow_post_mean_plot, dates=data.loc[:forecast_end].index, legend=days)
```


```python
plt.show(fig)
```


![png](output_28_0.png)


Okay, now this is interesting! First, we can see it takes a while for the model to learn the day-of-week effects. Once they stabilize, we have a few clear takeaways:
- Saturday and Sunday have the highest sales, followed by Friday
- Monday through Thursday sales are also very similar, with coefficients between -0.1 to -0.2.
- These effects in the state space are additive on the log scale. Remember the Poisson DGLM has a log-link function:
$$\log(\mu_t) = \lambda_t$$
$$\lambda_t = F_t^{'} \theta_t$$

If we want to interpret these effects in terms of actual sales, we need to recognize that they are additive and on the log scale in the state space. In terms of the prior mean, the effect is multiplicative. First, we can decompose the linear predictor into seasonal and other terms:
$$F_t^{'} \theta_t = F_{seas, t}^{'} \theta_{seas, t} + F_{other, t}^{'} \theta_{other, t}$$

Then think in terms of the conjugate prior:

$$\mu_t = e^{F_{seas, t}^{'} \theta_{seas, t}} * e^{F_{other, t}^{'} \theta_{other, t}}$$

The regression vector F_seas is just a 0-1 indicator to pluck out the correct day's seasonal effect. So to interpret each day's _multiplicative_ effect on sales, we take the exponent of the graph above:


```python
fig, ax = plt.subplots(1,1)
ax = plot_coef(fig, ax, np.exp(dow_post_mean_plot), dates=data.loc[:forecast_end].index, legend=days)
```


```python
plt.show(fig)
```


![png](output_32_0.png)


Perfect, this is very clear! A multiplicative seasonal effect of 1 has no effect on Sales. Anything larger than 1 boosts sales, and smaller than 1 reduces them.

Saturday and Sunday have around 30-40% higher sales than the average day, and Friday has around 10% higher sales. Monday-Thursday all have between 10-20% fewer sales than the average day.

The long term trends look fairly stable, which is natural - shopping habits change slowly over time. Part of that also comes from our model definition; The discount factor on the seasonality is very close to 1, so we discount historical information very slowly. If we believed that these trends changed more rapidly over time, we could re-run the analysis with a lower discount factor, using the parameter delseas as an argument to the analysis function.

### Conclusions

In this example we've used the PyBATS package to complete an analysis of simulated sales data. We:
- Used the 'analysis' function to define a Poisson DGLM with the first 21 days of data. It then performed online model updating and forecasting, 1-7 days ahead.
- Analyzed the 1-day ahead forecasts, and defined two error metrics on our point forecasts.
- Plotted the forecasts, and saw the added uncertainty caused by holidays, and the very strong day-of-week effects.
- Took a deep-dive into those day-of-week effects, plotting their effect on sales.

There's plenty more that we could have explored here as well:
- Looked at forecasts further into the future. How accurate are our 7-day ahead forecasts, and are they also well calibrated?
- What about other components to the state vector. We could example the trend term, which in this model is just the intercept. That would reveal underlying average sales over time. We could examine the regression coefficients on Price and Promotion, or the holiday effects as well. To interpret them, we would need to transform from the log scale into the space of the conjugate prior, just as we did with the seasonal effects.
- Finally, we might be interested in forecasting totals over the next week or month. This type of forecasting requires drawing joint samples over 1:k days into the future, and then taking a sum over each sample from the forecast distribution. This is known as _path forecasting_, and can be accomplished with the method path_forecast.


```python

```
